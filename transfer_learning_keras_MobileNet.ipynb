{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_keras_MobileNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/Resume/blob/master/transfer_learning_keras_MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-id-i26CUhB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL='https://github.com/aditya9898/transfer-learning/tree/master/train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvtWI5-iUlY8",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow only CNN on MNIST with MiniBatch evaluation\n",
        "\n",
        "- From [Deep Learning For Beginners Using Transfer Learning In Keras](https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e) by Aditya Anantharamam in [towardsdatascience.com](https://towardsdatascience.com).\n",
        "\n",
        "    - Author: [Aditya Anantharaman](https://github.com/aditya9898)\n",
        "    - GitHub Repository: https://github.com/aditya9898/transfer-learning/\n",
        "\n",
        "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_mxX64rvvmx",
        "colab_type": "text"
      },
      "source": [
        "## We'll try to answer thee big questions:\n",
        "\n",
        "### What is transfer learning ?\n",
        "### Why does transfer learning work so well ?\n",
        "### How can I coding an image recognizer using transfer learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLV4aNUtwFAB",
        "colab_type": "text"
      },
      "source": [
        "## What Is Transfer Learning ?\n",
        "\n",
        "If not for Transfer Learning, Machine Learning is a pretty tough thing to do for an absolute beginner. At the lowest level, machine learning involves computing a function that maps some inputs to their corresponding outputs. Though the function itself is just a bunch of addition and multiplication operations, when passed through a non linear activation function and stacking a bunch of these layers together, **functions can be made, to learn literally anything**, Provided there’s enough data to learn from, and an enormous amount of computational power.\n",
        "\n",
        "### Welcome to Deep Learning.\n",
        "\n",
        "Convolutional Neural Networks can learn extremely complex mapping functions when trained on enough data. We can’t yet understand how a convolutional net learns such complicated functions.\n",
        "\n",
        "At a base level, the weights of a CNN (Convolutional Neural Network) consist of **filters**. Think of a filter as an $(n*n)$ matrix which consists of certain numbers. Now this filter is **convoluted(slide and multiply)** through the provided image. Assume the input image is of size $(10,10)$ and the filter is of size $(3,3)$, first the filter is multiplied with the 9 pixels on the top-left of the input image, this multiplication produces another $(3,3)$ matrix. The values of the 9 pixels of this matrix are summed up and this value becomes a single pixel value on the top-left of **layer_2** of the CNN.\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://miro.medium.com/max/700/1*3aT9KWCeQ6wIYdLLhD4mCw.png\" />\n",
        "  </center>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xtt7MQ8wyPd",
        "colab_type": "text"
      },
      "source": [
        "Basically the training of a CNN involves, finding of the right values on each of the filters so that an input image when passed through the multiple layers, activates certain neurons of the last layer so as to predict the correct class.\n",
        "**bold text**\n",
        "Though training a CNN from scratch is possible for small projects, most applications require the training of very large CNN’s and this as you guessed, takes extremely huge amounts of processed data and computational power. And both of these are not found so easily these days.\n",
        "\n",
        "**That’s where transfer learning comes into play**. In transfer learning, we take the pre-trained weights of an already trained model(one that has been trained on millions of images belonging to 1000’s of classes, on several high power GPU’s for several days) and use these already learned features to predict new classes.\n",
        "\n",
        "***The advantages of transfer learning are that:***\n",
        "\n",
        "> ***1: There is no need of an extremely large training dataset.***\n",
        "\n",
        "> ***2: Not much computational power is required.As we are using pre-trained weights and only have to learn the weights of the last few layers.***\n",
        "\n",
        "There are several models that have been trained on the image net dataset and have been open sourced.\n",
        "\n",
        "For example, VGG-16, VGG-19, Inception-V3 etc. For more details about each of these models, read the official keras documentation [here](https://keras.io/applications/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJWOgPqqxVqz",
        "colab_type": "text"
      },
      "source": [
        "## Why Does Transfer Learning Work So Well ?\n",
        "\n",
        "To learn why transfer learning works so well, we must first look at what the different layers of a convolutional neural network are really learning.\n",
        "When we train a deep convolutional neural network on a dataset of images, during the training process, the images are passed through the network by applying several filters on the images at each layer. The values of the filter matrices are multiplied with the activations of the image at each layer. The activations coming out of the final layer are used to find out which class the image belongs to.\n",
        "\n",
        "When we train a deep network, out goal is to find the optimum values on each of these filter matrices so that when an image is propagated through the network, the output activations can be used to accurately find the class to which the image belongs. The process used to find these filter matrix values is gradient descent.\n",
        "\n",
        "When we train a conv net on the imagenet dataset and then take a look at what the filters on each layer of the conv net has learnt to recognize, or what each filter gets activated by, we are able to see something really interesting.\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://miro.medium.com/max/700/1*jPCEik198_CjtmSL2H6o4g.png\" />\n",
        "  </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77AkAjkixiuh",
        "colab_type": "text"
      },
      "source": [
        "The filters on the first few layers of the conv net learn to recognize colors and certain horizontal and vertical lines.\n",
        "\n",
        "The next few layers slowly learn to recognize trivial shapes using the lines and colors learnt in the previous layers.\n",
        "\n",
        "Then the next layers learn to recognize textures, then parts of objects like legs, eyes, nose etc.\n",
        "\n",
        "Finally the filters in the last layers get activated by whole objects like dogs, cars etc.\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://miro.medium.com/max/700/1*1Y6HZxK-lOmqB8KnizTCow.png\" />\n",
        "  </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqzenRt6xvrh",
        "colab_type": "text"
      },
      "source": [
        "Now lets get to transfer learning. The reason why it works so well is that, we use a network which is pretrained on the imagenet dataset and this network has already learnt to recognize the trivial shapes and small parts of different objects in its initial layers. By using a pretrained network to do transfer learning, we are simply adding a few dense layers at the end of the pretrained network and learning what combination of these already learnt features help in recognizing the objects in our new dataset.\n",
        "\n",
        "Hence we are training only a few dense layers. Furthermore, we are using a combination of these already learnt trivial features to recognize new objects. All this helps in making the training process very fast and require very less training data compared to training a conv net from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt7sM4u3xi0T",
        "colab_type": "text"
      },
      "source": [
        "## Heres how to build an actual image recognition model using transfer learning in Keras.\n",
        "\n",
        "The model that we’ll be using here is the [MobileNet](https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299).\n",
        "\n",
        "Mobile net is a model which gives reasonably good imagenet classification accuracy and occupies very less space. (17 MB according to keras docs).\n",
        "\n",
        "Dependencies Required :\n",
        "- Keras (with tensorflow backend)\n",
        "- Numpy\n",
        "- Matplotlib\n",
        "- Pandas\n",
        "\n",
        "#### Data Requirement:\n",
        "\n",
        "- The training data must be stored in a particular format in order to be fed into the network to train. We will be using ImageDataGenerator, available in keras to train our model on the available data. That way the process becomes much simpler in terms of code.\n",
        "\n",
        "- There must be a main data folder, inside that data folder, there must be a folder for each class of data containing the corresponding images. The names of the folders must be the names of their respective classes.\n",
        "\n",
        "## The building of a model is a 3 step process:\n",
        "\n",
        "> 1. Importing the pre-trained model and adding the dense layers.\n",
        "\n",
        "> 2. Loading train data into ImageDataGenerators.\n",
        "\n",
        "> 3. Training and Evaluating model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yevUmBl1xi7d",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmcG4hcTyvwT",
        "colab_type": "text"
      },
      "source": [
        "# Let the Coding Begin!\n",
        "\n",
        "**Usage NOTE!** Use `Shift+Enter` to step through this notebook, executing the code as you go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v61lH7RKy5i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Context:\n",
        "    VERBOSE=False    # True for extensive logging during execution.\n",
        "    QUIET=False      # True for minimal logging during execution.\n",
        "    WARNINGS=False   # True to enable display of annoying but rarely useful messages."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGj5JAQ0zAIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "321b08ec-5ecb-4ad3-811b-0cd646e47b56"
      },
      "source": [
        "#@title Check Runtime\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import timeit\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from contextlib import redirect_stderr\n",
        "\n",
        "# Suppress Tensorflow log spew.\n",
        "if Context.WARNINGS:\n",
        "    import keras    \n",
        "else:\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "    # Suppress Keras log spew.\n",
        "    with redirect_stderr(open(os.devnull, \"w\")):\n",
        "        import keras    \n",
        "\n",
        "try:\n",
        "   device_name = os.environ['COLAB_TPU_ADDR']\n",
        "   TPU_ADDRESS = 'grpc://' + device_name\n",
        "   print(f'Running with TPU acceleration at {TPU_ADDRESS}')\n",
        "except KeyError:\n",
        "  GPU_NAME = tf.test.gpu_device_name()\n",
        "  if GPU_NAME.startswith('/device:GPU'): \n",
        "      print(f\"Running with GPU acceleration at {GPU_NAME}\")\n",
        "  else:\n",
        "      print(\"Running on normal CPU without GPU acceleration.\")\n",
        "        \n",
        "def elapsed_time(func, *args, msg=''):\n",
        "    ''' Display the elapsed time of the function.\n",
        "        Return the function value.\n",
        "    '''\n",
        "    stime = time.time()\n",
        "    result = func(*args)\n",
        "    etime = time.time() - stime\n",
        "    log(msg + \"Elapsed test time: {0}\", timedelta(seconds=etime))\n",
        "    return result  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on normal CPU without GPU acceleration.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJT8a2-wUlg8",
        "colab_type": "text"
      },
      "source": [
        "## Copy the Transfer Learning Training image to here.\n",
        "\n",
        "This uses some nasty tricks to get around githubusercontent.com's refusal to allow wget downloading of entire directories.  This is really nasty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrAGqmEMUkvq",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Nasty File Transfer Utility Tools\n",
        "import numpy as np\n",
        "import requests\n",
        "import shutil\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "ds = np.DataSource()\n",
        "def copyHere(URL, toPath, quiet=False):\n",
        "    toDir, toFile = os.path.split(toPath)\n",
        "    toPath = os.path.join(toDir, toFile)\n",
        "    if os.path.exists(toPath):\n",
        "        if not quiet:\n",
        "            print(f\"- Skipped copy of existing file {toPath}.\")\n",
        "    else:\n",
        "        if ds.exists(URL):\n",
        "            if not toFile:\n",
        "                urlPrefix, toFile = os.path.split(URL)\n",
        "            response = requests.get(URL, stream=True)\n",
        "            if toDir:\n",
        "                if not os.path.exists(toDir): \n",
        "                  print(f\"- Creating directory '{toDir}'.\")\n",
        "                  os.makedirs(toDir)\n",
        "            with open(toPath, 'wb') as fin: shutil.copyfileobj(response.raw, fin)\n",
        "            if not quiet:\n",
        "                print(f\"- Copied {URL} to {toPath}.\")\n",
        "        else:\n",
        "            print(f\"** Sorry, can't copy '{URL}' to '{toPath}'.\")\n",
        "\n",
        "def get_url_files(url, ext='', params={}):\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.ok:\n",
        "        response_text = response.text\n",
        "    else:\n",
        "        return response.raise_for_status()\n",
        "    soup = BeautifulSoup(response_text, 'html.parser')\n",
        "    parent = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
        "    files = [os.path.basename(f) for f in parent]    \n",
        "    return files            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3svtOm5lmP0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "abd52366-94ca-4be8-d835-fb9035872ad5"
      },
      "source": [
        "filename = 'Z.jpg'\n",
        "REPO     = 'https://raw.githubusercontent.com/aditya9898/transfer-learning/'\n",
        "BRANCH   = 'master/'\n",
        "DIR      = 'train/cats/'\n",
        "TMPDIR   = 'tmpData'\n",
        "\n",
        "url = 'https://github.com/aditya9898/transfer-learning/tree/master/'\n",
        "ext = 'jpg'\n",
        "\n",
        "print(\"- Please wait ... this may take a few minutes.\")\n",
        "for imgdir in ['train/cats', 'train/dogs', 'train/horses']:\n",
        "    TODIR = os.path.join(TMPDIR, imgdir)\n",
        "    files =  get_url_files(url + imgdir, ext)\n",
        "    print(f\"- Downloading all images to {TODIR}:\")\n",
        "    for img in files:\n",
        "        URL = os.path.join(REPO, BRANCH, imgdir, img)\n",
        "        toPath  = os.path.join(TODIR, img)\n",
        "        #print(f'- Copy {URL} to {toPath}')\n",
        "        copyHere(URL, toPath, quiet=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Please wait ... this may take a few minutes.\n",
            "- Downloading all images to tmpData/train/cats:\n",
            "- Downloading all images to tmpData/train/dogs:\n",
            "- Downloading all images to tmpData/train/horses:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7S2tCPi0V5j",
        "colab_type": "text"
      },
      "source": [
        "## Here are the main dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQVyLi2FUk_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA6XbgHiUmm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKCt3Rv0UqWf",
        "colab_type": "text"
      },
      "source": [
        "Then import the pre-trained MobileNet model. The Mobilenet (trained on the imagenet dataset for a thousand classes) will have a last layer consisting of 1000 neurons (one for each class). We want as many neurons in the last layer of the network as the number of classes we wish to identify. So we discard the 1000 neuron layer and add our own last layer for the network.\n",
        "\n",
        "This can be done by setting (IncludeTop=False) when importing the model.\n",
        "So suppose you want to train a dog breed classifier to identify 120 different breeds, we need 120 neurons in the final layer. This can be done using the following code.\n",
        "\n",
        "*This is **step 1** of the process. Importing and building the required model.*\n",
        "\n",
        "We import the MobileNet model without its last layer and add a few dense layers so that our model can learn more complex functions. The dense layers must have the relu activation function and the last layer,which contains as many neurons as the number of classes must have the softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItcoOMNaUsN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "27eb1bb5-f6d7-4d67-9665-441fb4d1cdef"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet', include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(3,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PiO-eJ9VGG4",
        "colab_type": "text"
      },
      "source": [
        "### Next we make a model based on the architecture we have provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzeUByfTUvsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "#specify the inputs\n",
        "#specify the outputs\n",
        "#now a model has been created based on our architecture"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn6VnS10VOmc",
        "colab_type": "text"
      },
      "source": [
        "### To check the architecture of our model, we simply need to use this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqy_ZyFzVNXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LopFqifVTm1",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our model, as we will be using the pre-trained weights, that our model has been trained on (imagenet dataset), we have to set all the weights to be non-trainable. We will only be training the last Dense layers that we have made previously. The code for doing this is given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0G7tlygVapE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9DRGtmZVSIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29acb22b-59ca-4cad-eec0-26b7afac5d31"
      },
      "source": [
        "# ./train/ has been downloaded from https://github.com/aditya9898/transfer-learning/tree/master/train\n",
        "#\n",
        "train_generator=train_datagen.flow_from_directory(os.path.join(TMPDIR, 'train'), \n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 197 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnqQQwKF2O_4",
        "colab_type": "text"
      },
      "source": [
        "Next we move onto **Step 3**, training the model on the dataset.\n",
        "\n",
        "For this we first compile the model that we made, and then train our model with our generator. \n",
        "\n",
        "### This will take a while..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtTQm5oI2Z-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b254edb0-ace2-42f5-f130-e47e87793b18"
      },
      "source": [
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 47s 8s/step - loss: 1.2102 - acc: 0.5677\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.2000 - acc: 0.9198\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.1455 - acc: 0.9386\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.0710 - acc: 0.9840\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.0560 - acc: 0.9787\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.0223 - acc: 0.9947\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.1559 - acc: 0.9652\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 42s 7s/step - loss: 0.2366 - acc: 0.9531\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.1355 - acc: 0.9574\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.2001 - acc: 0.9066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efcc6180cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtzQemBH2hqE",
        "colab_type": "text"
      },
      "source": [
        "With this, we will have trained a model. The trained model can then be used to predict which class a new unseen image belongs to, by using:\n",
        "\n",
        "```\n",
        "    model.predict(new_image).\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18AZjJIB2dCP",
        "colab_type": "text"
      },
      "source": [
        "As always, Happy Learning.\n",
        "\n",
        "### End of notebook."
      ]
    }
  ]
}